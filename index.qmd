# LangChain ğŸ¦œğŸ”—

::: footer
[LangChain dokumentasjon](https://python.langchain.com/docs/introduction/)
:::

## Hva er det?

> LangChain is a framework for developing applications powered by large language
> models.

. . .

- Integrasjon mellom tilbydere av sprÃ¥kmodeller
- GjÃ¸r ikke noe beregning selv
	- Alt gjÃ¸res av eksterne tjenester

## Hvorfor

- "SprÃ¥k" for Ã¥ kjedesammen elementer til sprÃ¥kmodellene
- Abstraksjon av hendige funksjoner

---

### Bygge ledetekst

```{python}
from langchain_core.prompts import ChatPromptTemplate

template = "Translate the following into {language}:"
prompt = ChatPromptTemplate.from_messages(
	[("system", template), ("user", "{text}")]
)
```

---

### Bruke ledetekst

```{python}
specified = prompt.invoke({"language": "Swedish", "text": "Hi everybody!"})
specified.to_messages()
```

---

### Opprette sprÃ¥kmodell

::: {.panel-tabset}
#### Vertex AI

```{python}
from langchain_google_vertexai import ChatVertexAI

llm = ChatVertexAI(model_name="gemini-1.5-flash-002")
```

#### OpenAI

```{.python}
import os

from langchain_openai import AzureChatOpenAI

llm = AzureChatOpenAI(
    azure_endpoint=os.environ["AZURE_OPENAI_ENDPOINT"],
    azure_deployment=os.environ["AZURE_OPENAI_DEPLOYMENT_NAME"],
    openai_api_version=os.environ["AZURE_OPENAI_API_VERSION"],
)
```
:::

::: footer
- [Referanse til `Gemini 1.5 Flash` pÃ¥ GCP](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/gemini-1.5-flash-002)
- [Referanse til `ChatVertexAI` hos LangChain](https://python.langchain.com/docs/integrations/chat/google_vertex_ai_palm/)
- [Referanse til `AzureChatOpenAI` hos LangChain](https://python.langchain.com/docs/integrations/chat/azure_chat_openai/)
:::

---

### Bruke sprÃ¥kmodellen

```{python}
llm.invoke(specified.to_messages())
```

---

### Kjedesammen elementer

```{python}
from langchain_core.output_parsers import StrOutputParser

# Opprette en kjede som forenkler Ã¥ sette sammen ledetekst, sprÃ¥kmodell og tolkning av svaret
chain = prompt | llm | StrOutputParser()
# All bruk av LangChain fungerer pÃ¥ samme mÃ¥te:
chain.invoke(
	{"language": "Icelandic", "text": "Hi to every Data Scientist!"}
)
```

---

### Abstraksjon

```{.python}
# Kall pÃ¥ kjeden og produser output
chain.invoke({...})
# StrÃ¸m svaret mens det blir produsert
chain.stream({...})
# Hent flere svar samtidig for raskere prosessering
chain.batch([{...}, {...}])
# Finnes ogsÃ¥ som asynkrone metoder hvis det trengs
chain.ainvoke({...})
```

---

### Bakdelen

- Fint nÃ¥r oppsettet er `ledetekst -> sprÃ¥kmodell -> output`
- Ved mer kompliserte kjeder sÃ¥ blir det vanskelig
	- MÃ¥ bruke mange spesialiserte `Runnable`-er
	- Skriver ikke vanlig Python

# LangGraph ğŸ¦œğŸ•¸ï¸

::: footer
[LangGraph dokumentasjon](https://langchain-ai.github.io/langgraph/)
:::

## Hva er det?
 
 > Build robust and stateful multi-actor applications with LLMs by modeling
 > steps as edges and nodes in a graph.

 . . .

 - Ikke egentlig noe ny funksjonalitet over LangChain
 - MEN, enklere Ã¥ koble sammen ulike kjeder
	- Bruker vanlige Python metoder!

. . .

- MÃ¥ ikke vÃ¦re `multi-actor` ğŸ˜…

